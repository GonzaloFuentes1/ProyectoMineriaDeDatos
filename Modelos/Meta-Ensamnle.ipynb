{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_clean = []\n",
    "df_list = []\n",
    "for i in range(10):\n",
    "    df = pd.read_csv(f\"Datasets/Duplicated{i+1}MeanPastMatches.csv\")\n",
    "    df.drop_duplicates(inplace=True)\n",
    "    df.dropna(inplace=True)\n",
    "    index_limpio = set(df[\"index\"])\n",
    "\n",
    "    df_list.append(df)\n",
    "    index_clean.append(index_limpio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_set = index_clean[0]\n",
    "for i in index_clean:\n",
    "    init_set = init_set.intersection(i)\n",
    "final_set = list(init_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "62093"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(final_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# En este caso X_train, X_val y X_test son listas de dataframes\n",
    "X_train, X_val, X_test = [], [], []\n",
    "y_train, y_val, y_test = [], [], []\n",
    "for i in range(10):\n",
    "    df = df_list[i][df_list[i][\"index\"].isin(final_set)]\n",
    "    df = pd.get_dummies(df, columns=[\"surface\", \"player1_hand\", \"player2_hand\", \"best_of\"], dtype=int)\n",
    "    X = df.drop([\"label\"],axis = 1)\n",
    "    y = df[\"label\"]\n",
    "\n",
    "    X_train_df = X[X[\"tourney_date\"] < 20150101].drop(\"tourney_date\", axis=1) # 2000 - 2014\n",
    "    X_val_df = X[(X[\"tourney_date\"]>= 20150101) & (X[\"tourney_date\"] < 20190101)].drop(\"tourney_date\", axis=1) # 2015 - 2018\n",
    "    X_test_df = X[X[\"tourney_date\"] >= 20190101].drop(\"tourney_date\", axis=1) # 2018 - 2024\n",
    "\n",
    "    y_train_aux, y_val_aux, y_test_aux = y[X_train_df.index], y[X_val_df.index], y[X_test_df.index]\n",
    "    \n",
    "    X_train.append(X_train_df)\n",
    "    X_val.append(X_val_df)\n",
    "    X_test.append(X_test_df)\n",
    "\n",
    "    y_train.append(y_train_aux)\n",
    "    y_val.append(y_val_aux)\n",
    "    y_test.append(y_test_aux)\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño de los sets: \n",
      " Set training 0.6465140998180149 \n",
      " Set val 0.17191954004477156 \n",
      " Set test 0.18156636013721353\n"
     ]
    }
   ],
   "source": [
    "total = len(X_train[1]) + len(X_val[1]) + len(X_test[1])\n",
    "print(f\"Tamaño de los sets: \\n Set training {len(X_train[1])/total} \\n Set val {len(X_val[1])/total} \\n Set test {len(X_test[1])/total}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n",
      "0.5\n",
      "0.5\n"
     ]
    }
   ],
   "source": [
    "# Veamos el desbalance en cada particion, deberia ser totalmente balanceada\n",
    "\n",
    "print(sum(y_train[0]==1) / len(y_train[0]))\n",
    "\n",
    "print(sum(y_val[0]==1) / len(y_val[0]))\n",
    "\n",
    "print(sum(y_test[0]==1) / len(y_test[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Set número 1\n",
      "Nuevo mejor modelo (2, 5), con 0.6463700234192038\n",
      "Nuevo mejor modelo (2, 10), con 0.6492271662763466\n",
      "Nuevo mejor modelo (2, 15), con 0.6550351288056206\n",
      "\n",
      "Set número 2\n",
      "Nuevo mejor modelo (2, 5), con 0.6451053864168619\n",
      "Nuevo mejor modelo (2, 10), con 0.651615925058548\n",
      "Nuevo mejor modelo (2, 15), con 0.6523185011709602\n",
      "Nuevo mejor modelo (2, 25), con 0.6524590163934426\n",
      "Nuevo mejor modelo (2, 35), con 0.6532084309133489\n",
      "\n",
      "Set número 3\n",
      "Nuevo mejor modelo (2, 5), con 0.6441686182669789\n",
      "Nuevo mejor modelo (2, 10), con 0.6539110070257611\n",
      "Nuevo mejor modelo (2, 15), con 0.6543325526932084\n",
      "Nuevo mejor modelo (2, 20), con 0.6549882903981264\n",
      "\n",
      "Set número 4\n",
      "Nuevo mejor modelo (2, 5), con 0.6452459016393443\n",
      "Nuevo mejor modelo (2, 10), con 0.6538173302107728\n",
      "Nuevo mejor modelo (2, 15), con 0.6556908665105387\n",
      "Nuevo mejor modelo (2, 20), con 0.6557377049180327\n",
      "Nuevo mejor modelo (2, 25), con 0.6560187353629977\n",
      "\n",
      "Set número 5\n",
      "Nuevo mejor modelo (2, 5), con 0.6488056206088993\n",
      "Nuevo mejor modelo (2, 10), con 0.6523185011709602\n",
      "Nuevo mejor modelo (2, 15), con 0.6542857142857142\n",
      "\n",
      "Set número 6\n",
      "Nuevo mejor modelo (2, 5), con 0.6465105386416862\n",
      "Nuevo mejor modelo (2, 10), con 0.6527400468384075\n",
      "Nuevo mejor modelo (2, 15), con 0.6533021077283372\n",
      "Nuevo mejor modelo (2, 20), con 0.6540515222482436\n",
      "\n",
      "Set número 7\n",
      "Nuevo mejor modelo (2, 5), con 0.6463700234192038\n",
      "Nuevo mejor modelo (2, 10), con 0.6538173302107728\n",
      "Nuevo mejor modelo (2, 20), con 0.6551288056206089\n",
      "\n",
      "Set número 8\n",
      "Nuevo mejor modelo (2, 5), con 0.6471194379391101\n",
      "Nuevo mejor modelo (2, 10), con 0.6527400468384075\n",
      "Nuevo mejor modelo (2, 25), con 0.6529742388758782\n",
      "\n",
      "Set número 9\n",
      "Nuevo mejor modelo (2, 5), con 0.6448711943793911\n",
      "Nuevo mejor modelo (2, 10), con 0.6544730679156908\n",
      "Nuevo mejor modelo (2, 15), con 0.6554566744730679\n",
      "Nuevo mejor modelo (2, 35), con 0.6555035128805621\n",
      "\n",
      "Set número 10\n",
      "Nuevo mejor modelo (2, 5), con 0.642903981264637\n",
      "Nuevo mejor modelo (2, 10), con 0.6540515222482436\n",
      "Nuevo mejor modelo (2, 15), con 0.6543793911007025\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import metrics\n",
    "\n",
    "range_T = [5*(i+1) for i in range(8)] # Modelos base\n",
    "\n",
    "for i in range(len(X_train)):\n",
    "    print(f\"\\nSet número {i+1}\")\n",
    "    # Por cada info\n",
    "    set_X_train = X_train[i]\n",
    "    set_X_val = X_val[i]\n",
    "\n",
    "    set_y_train = y_train[i]\n",
    "    set_y_val = y_val[i]\n",
    "\n",
    "    best_tuple = ()\n",
    "    best_acc = 0\n",
    "\n",
    "\n",
    "    for t_ in range_T:\n",
    "        clf = AdaBoostClassifier(DecisionTreeClassifier(max_depth=2), n_estimators=t_, random_state=0)\n",
    "        clf.fit(set_X_train, set_y_train)\n",
    "        y_pred = clf.predict(set_X_val)\n",
    "        acc = metrics.accuracy_score(set_y_val, y_pred)\n",
    "        if acc > best_acc:\n",
    "            best_acc = acc\n",
    "            best_tuple = (2 , t_)\n",
    "            print(f\"Nuevo mejor modelo {best_tuple}, con {best_acc}\")\n",
    "        \n",
    "    for t_ in range_T:\n",
    "        clf = AdaBoostClassifier(DecisionTreeClassifier(max_depth=3), n_estimators=t_, random_state=0)\n",
    "        clf.fit(set_X_train, set_y_train)\n",
    "        y_pred = clf.predict(set_X_val)\n",
    "        acc = metrics.accuracy_score(set_y_val, y_pred)\n",
    "        if acc > best_acc:\n",
    "            best_acc = acc\n",
    "            best_tuple = (3 , t_)\n",
    "            print(f\"Nuevo mejor modelo {best_tuple}, con {best_acc}\")\n",
    "    for t_ in range_T:\n",
    "        clf = AdaBoostClassifier(DecisionTreeClassifier(max_depth=4), n_estimators=t_, random_state=0)\n",
    "        clf.fit(set_X_train, set_y_train)\n",
    "        y_pred = clf.predict(set_X_val)\n",
    "        acc = metrics.accuracy_score(set_y_val, y_pred)\n",
    "        if acc > best_acc:\n",
    "            best_acc = acc\n",
    "            best_tuple = (4 , t_)\n",
    "            print(f\"Nuevo mejor modelo {best_tuple}, con {best_acc}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ahora que tenemos los mejores hiperparámetros, hacemos un modelo a partir de ese \n",
    "hiperparameters = {1:(2, 15), 2:(2, 35), 3:(2, 20),\n",
    "                   4:(2, 25), 5:(2, 15), 6:(2, 20),\n",
    "                   7:(2, 20), 8:(2, 25), 9:(2, 35),\n",
    "                   10:(2, 15)}\n",
    "models = []\n",
    "for i in range(len(hiperparameters)):\n",
    "    depth, t_ = hiperparameters[i+1]\n",
    "    model = AdaBoostClassifier(DecisionTreeClassifier(max_depth=depth), n_estimators=t_, random_state=0)\n",
    "    model.fit(X_train[i], y_train[i])\n",
    "    models.append(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ahora, hacemos el meta-ensamble:\n",
    "X = []\n",
    "for model in models:\n",
    "    prediction = model.predict(set_X_train)\n",
    "    X.append(prediction)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
